---
sidebar: sidebar 
permalink: trident-use/worker-node-prep.html 
keywords: storage class, manage storage class, storage classes, kubernetes storage classes, worker node, nfs, iscsi, kubernetes clusters, self-healing, healing, nvme, tcp 
summary: 'Tous les nœuds de travail du cluster Kubernetes doivent pouvoir monter les volumes que vous avez provisionnés pour vos pods.  Si vous utilisez le pilote ontap-nas, ontap-nas-economy ou ontap-nas-flexgroup pour l"un de vos serveurs backend, vos nœuds de travail ont besoin des outils NFS.  Sinon, ils ont besoin des outils iSCSI.' 
---
= Préparer le nœud de travail
:hardbreaks:
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Tous les nœuds de travail du cluster Kubernetes doivent pouvoir monter les volumes que vous avez provisionnés pour vos pods.  Pour préparer les nœuds de travail, vous devez installer les outils NFS, iSCSI, NVMe/TCP ou FC en fonction du pilote que vous avez sélectionné.



== Choisir les bons outils

Si vous utilisez une combinaison de pilotes, vous devez installer tous les outils requis pour vos pilotes.  Les versions récentes de Red Hat Enterprise Linux CoreOS (RHCOS) intègrent ces outils par défaut.

.Outils NFS
link:https://docs.netapp.com/us-en/trident/trident-use/worker-node-prep.html#nfs-volumes["Installez les outils NFS"]si vous utilisez : `ontap-nas` , `ontap-nas-economy` , `ontap-nas-flexgroup` , `azure-netapp-files` , `gcp-cvs` .

.Outils iSCSI
link:https://docs.netapp.com/us-en/trident/trident-use/worker-node-prep.html#install-the-iscsi-tools["Installez les outils iSCSI"]si vous utilisez : `ontap-san` , `ontap-san-economy` , `solidfire-san` .

.Outils NVMe
link:https://docs.netapp.com/us-en/trident/trident-use/worker-node-prep.html#nvmetcp-volumes["Installez les outils NVMe"]si vous utilisez `ontap-san` pour le protocole NVMe/TCP (Nonvolatile Memory Express sur TCP).


NOTE: NetApp recommande ONTAP 9.12 ou une version ultérieure pour NVMe/TCP.

.Outils SCSI sur FC
Se référer àlink:https://docs.netapp.com/us-en/ontap/san-config/configure-fc-nvme-hosts-ha-pairs-reference.html["Méthodes de configuration des hôtes SAN FC et FC-NVMe"] pour plus d'informations sur la configuration de vos hôtes SAN FC et FC-NVMe.

link:https://docs.netapp.com/us-en/trident/trident-use/worker-node-prep.html#install-the-fc-tools["Installez les outils FC"]si vous utilisez `ontap-san` avec sanType `fcp` (SCSI sur FC).

Points à prendre en compte : * SCSI sur FC est pris en charge dans les environnements OpenShift et KubeVirt.  * Le protocole SCSI sur FC n'est pas pris en charge sur Docker.  * L'auto-réparation iSCSI n'est pas applicable à SCSI sur FC.



== Découverte de services de nœuds

Trident tente de détecter automatiquement si le nœud peut exécuter des services iSCSI ou NFS.


NOTE: La découverte de services de nœuds identifie les services découverts, mais ne garantit pas que ces services soient correctement configurés.  Inversement, l'absence de service détecté ne garantit pas l'échec du montage du volume.

.Revoir les événements
Trident crée des événements pour que le nœud puisse identifier les services découverts.  Pour consulter ces événements, exécutez :

[listing]
----
kubectl get event -A --field-selector involvedObject.name=<Kubernetes node name>
----
.Avis sur les services découverts
Trident identifie les services activés pour chaque nœud sur le CR du nœud Trident .  Pour afficher les services détectés, exécutez :

[listing]
----
tridentctl get node -o wide -n <Trident namespace>
----


== Volumes NFS

Installez les outils NFS en utilisant les commandes correspondant à votre système d'exploitation.  Assurez-vous que le service NFS est démarré au démarrage du système.

[role="tabbed-block"]
====
.RHEL 8+
--
[listing]
----
sudo yum install -y nfs-utils
----
--
.Ubuntu
--
[listing]
----
sudo apt-get install -y nfs-common
----
--
====

WARNING: Redémarrez vos nœuds de travail après l'installation des outils NFS pour éviter les échecs lors de l'attachement des volumes aux conteneurs.



== volumes iSCSI

Trident peut établir automatiquement une session iSCSI, analyser les LUN, découvrir les périphériques multipath, les formater et les monter sur un pod.



=== Capacités d'auto-réparation iSCSI

Pour les systèmes ONTAP , Trident exécute une auto-réparation iSCSI toutes les cinq minutes afin de :

. *Identifier* l'état de session iSCSI souhaité et l'état de session iSCSI actuel.
. *Comparer* l'état souhaité à l'état actuel pour identifier les réparations nécessaires.  Trident détermine les priorités de réparation et les situations où il convient d'anticiper les réparations.
. *Effectuer les réparations* nécessaires pour ramener l'état actuel de la session iSCSI à l'état souhaité.



NOTE: Les journaux d'activité d'auto-guérison se trouvent dans le `trident-main` conteneur sur le pod Daemonset respectif.  Pour consulter les journaux, vous devez avoir configuré `debug` à « vrai » lors de l'installation de Trident .

Les capacités d'auto-réparation de Trident iSCSI peuvent contribuer à prévenir :

* Sessions iSCSI obsolètes ou défaillantes pouvant survenir suite à un problème de connectivité réseau.  En cas de session inactive, Trident attend sept minutes avant de se déconnecter afin de rétablir la connexion avec un portail.
+

NOTE: Par exemple, si les secrets CHAP étaient renouvelés sur le contrôleur de stockage et que le réseau perdait sa connectivité, les anciens secrets CHAP (obsolètes) pourraient persister.  L'auto-réparation peut détecter cela et rétablir automatiquement la session pour appliquer les secrets CHAP mis à jour.

* Sessions iSCSI manquantes
* LUN manquants


Points à prendre en compte avant de mettre à niveau Trident

* Si seuls les igroups par nœud (introduits dans la version 23.04 et suivantes) sont utilisés, l'auto-réparation iSCSI lancera des analyses SCSI pour tous les périphériques du bus SCSI.
* Si seuls les igroups à portée backend (dépréciés depuis la version 23.04) sont utilisés, l'auto-réparation iSCSI lancera des analyses SCSI pour les ID LUN exacts sur le bus SCSI.
* Si une combinaison d'igroups par nœud et d'igroups à portée dorsale est utilisée, l'auto-réparation iSCSI lancera des analyses SCSI pour les ID LUN exacts sur le bus SCSI.




=== Installez les outils iSCSI

Installez les outils iSCSI en utilisant les commandes correspondant à votre système d'exploitation.

.Avant de commencer
* Chaque nœud du cluster Kubernetes doit avoir un IQN unique.  *Ceci est une condition préalable nécessaire*.
* Si vous utilisez RHCOS version 4.5 ou ultérieure, ou une autre distribution Linux compatible RHEL, avec le `solidfire-san` Si le pilote et Element OS 12.5 ou antérieur sont installés, assurez-vous que l'algorithme d'authentification CHAP est défini sur MD5. `/etc/iscsi/iscsid.conf` . Les algorithmes CHAP sécurisés conformes à la norme FIPS SHA1, SHA-256 et SHA3-256 sont disponibles avec Element 12.7.
+
[listing]
----
sudo sed -i 's/^\(node.session.auth.chap_algs\).*/\1 = MD5/' /etc/iscsi/iscsid.conf
----
* Lors de l'utilisation de nœuds de travail exécutant RHEL/Red Hat Enterprise Linux CoreOS (RHCOS) avec des volumes persistants iSCSI, spécifiez le `discard` L'option mountOption dans StorageClass permet d'effectuer une récupération d'espace en ligne. Se référer à https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/managing_file_systems/discarding-unused-blocks_managing-file-systems["Documentation Red Hat"^] .
* Assurez-vous d'avoir effectué la mise à jour vers la dernière version de `multipath-tools` .


[role="tabbed-block"]
====
.RHEL 8+
--
. Installez les paquets système suivants :
+
[listing]
----
sudo yum install -y lsscsi iscsi-initiator-utils device-mapper-multipath
----
. Vérifiez que la version d'iscsi-initiator-utils est 6.2.0.874-2.el7 ou ultérieure :
+
[listing]
----
rpm -q iscsi-initiator-utils
----
. Configurer la numérisation en mode manuel :
+
[listing]
----
sudo sed -i 's/^\(node.session.scan\).*/\1 = manual/' /etc/iscsi/iscsid.conf
----
. Activer le multipathing :
+
[listing]
----
sudo mpathconf --enable --with_multipathd y --find_multipaths n
----
+

NOTE: Assurer `/etc/multipath.conf` contient `find_multipaths no` sous `defaults` .

. Assurez-vous que `iscsid` et `multipathd` sont en cours d'exécution :
+
[listing]
----
sudo systemctl enable --now iscsid multipathd
----
. Activer et démarrer `iscsi` :
+
[listing]
----
sudo systemctl enable --now iscsi
----


--
.Ubuntu
--
. Installez les paquets système suivants :
+
[listing]
----
sudo apt-get install -y open-iscsi lsscsi sg3-utils multipath-tools scsitools
----
. Vérifiez que la version d'open-iscsi est 2.0.874-5ubuntu2.10 ou ultérieure (pour bionic) ou 2.0.874-7.1ubuntu6.1 ou ultérieure (pour focal) :
+
[listing]
----
dpkg -l open-iscsi
----
. Configurer la numérisation en mode manuel :
+
[listing]
----
sudo sed -i 's/^\(node.session.scan\).*/\1 = manual/' /etc/iscsi/iscsid.conf
----
. Activer le multipathing :
+
[listing]
----
sudo tee /etc/multipath.conf <<-EOF
defaults {
    user_friendly_names yes
    find_multipaths no
}
EOF
sudo systemctl enable --now multipath-tools.service
sudo service multipath-tools restart
----
+

NOTE: Assurer `/etc/multipath.conf` contient `find_multipaths no` sous `defaults` .

. Assurez-vous que `open-iscsi` et `multipath-tools` sont activés et en cours d'exécution :
+
[listing]
----
sudo systemctl status multipath-tools
sudo systemctl enable --now open-iscsi.service
sudo systemctl status open-iscsi
----
+

NOTE: Pour Ubuntu 18.04, vous devez découvrir les ports cibles avec `iscsiadm` avant de commencer `open-iscsi` pour que le démon iSCSI démarre.  Vous pouvez également modifier le `iscsi` service à démarrer `iscsid` automatiquement.



--
====


=== Configurer ou désactiver l'autoréparation iSCSI

Vous pouvez configurer les paramètres d'auto-réparation iSCSI Trident suivants pour corriger les sessions obsolètes :

* *Intervalle d'auto-réparation iSCSI* : Détermine la fréquence à laquelle l'auto-réparation iSCSI est invoquée (par défaut : 5 minutes).  Vous pouvez le configurer pour qu'il s'exécute plus fréquemment en définissant un nombre plus petit, ou moins fréquemment en définissant un nombre plus grand.


[NOTE]
====
Définir l'intervalle d'auto-réparation iSCSI à 0 arrête complètement l'auto-réparation iSCSI.  Nous ne recommandons pas de désactiver l'auto-réparation iSCSI ; elle ne doit être désactivée que dans certains cas, lorsque l'auto-réparation iSCSI ne fonctionne pas comme prévu ou à des fins de débogage.

====
* *Délai d'attente d'auto-réparation iSCSI* : Détermine la durée pendant laquelle l'auto-réparation iSCSI attend avant de se déconnecter d'une session défaillante et de tenter de se reconnecter (par défaut : 7 minutes).  Vous pouvez le configurer sur un nombre plus élevé afin que les sessions identifiées comme non saines doivent attendre plus longtemps avant d'être déconnectées, puis qu'une tentative de reconnexion soit effectuée, ou sur un nombre plus petit pour se déconnecter et se reconnecter plus tôt.


[role="tabbed-block"]
====
.Barre
--
Pour configurer ou modifier les paramètres d'auto-réparation iSCSI, transmettez le `iscsiSelfHealingInterval` et `iscsiSelfHealingWaitTime` paramètres lors de l'installation ou de la mise à jour de Helm.

L'exemple suivant configure l'intervalle d'auto-réparation iSCSI à 3 minutes et le délai d'attente d'auto-réparation à 6 minutes :

[listing]
----
helm install trident trident-operator-100.2506.0.tgz --set iscsiSelfHealingInterval=3m0s --set iscsiSelfHealingWaitTime=6m0s -n trident
----
--
.tridentctl
--
Pour configurer ou modifier les paramètres d'auto-réparation iSCSI, transmettez le `iscsi-self-healing-interval` et `iscsi-self-healing-wait-time` paramètres lors de l'installation ou de la mise à jour de tridentctl.

L'exemple suivant configure l'intervalle d'auto-réparation iSCSI à 3 minutes et le délai d'attente d'auto-réparation à 6 minutes :

[listing]
----
tridentctl install --iscsi-self-healing-interval=3m0s --iscsi-self-healing-wait-time=6m0s -n trident
----
--
====


== Volumes NVMe/TCP

Installez les outils NVMe en utilisant les commandes correspondant à votre système d'exploitation.

[NOTE]
====
* NVMe nécessite RHEL 9 ou une version ultérieure.
* Si la version du noyau de votre nœud Kubernetes est trop ancienne ou si le package NVMe n'est pas disponible pour votre version du noyau, vous devrez peut-être mettre à jour la version du noyau de votre nœud vers une version incluant le package NVMe.


====
[role="tabbed-block"]
====
.RHEL 9
--
[listing]
----
sudo yum install nvme-cli
sudo yum install linux-modules-extra-$(uname -r)
sudo modprobe nvme-tcp
----
--
.Ubuntu
--
[listing]
----
sudo apt install nvme-cli
sudo apt -y install linux-modules-extra-$(uname -r)
sudo modprobe nvme-tcp
----
--
====


=== Vérifier l'installation

Après l'installation, vérifiez que chaque nœud du cluster Kubernetes possède un NQN unique à l'aide de la commande :

[listing]
----
cat /etc/nvme/hostnqn
----

WARNING: Trident modifie le `ctrl_device_tmo` valeur permettant de s'assurer que NVMe ne renonce pas au chemin en cas de panne.  Ne modifiez pas ce paramètre.



== Volumes SCSI sur FC

Vous pouvez désormais utiliser le protocole Fibre Channel (FC) avec Trident pour provisionner et gérer les ressources de stockage sur le système ONTAP .



=== Prérequis

Configurez les paramètres réseau et de nœud requis pour FC.



==== Paramètres réseau

. Obtenez le WWPN des interfaces cibles.  Se référer à https://docs.netapp.com/us-en/ontap-cli//network-interface-show.html["affichage de l'interface réseau"^] pour plus d'informations.
. Obtenez le WWPN pour les interfaces sur l'initiateur (hôte).
+
Consultez les utilitaires correspondants du système d'exploitation hôte.

. Configurez le zonage sur le commutateur FC en utilisant les WWPN de l'hôte et de la cible.
+
Veuillez vous référer à la documentation du fournisseur du commutateur concerné pour plus d'informations.

+
Pour plus de détails, veuillez consulter la documentation ONTAP suivante :

+
** https://docs.netapp.com/us-en/ontap/san-config/fibre-channel-fcoe-zoning-concept.html["Aperçu du zonage Fibre Channel et FCoE"^]
** https://docs.netapp.com/us-en/ontap/san-config/configure-fc-nvme-hosts-ha-pairs-reference.html["Méthodes de configuration des hôtes SAN FC et FC-NVMe"^]






=== Installez les outils FC

Installez les outils FC en utilisant les commandes correspondant à votre système d'exploitation.

* Lors de l'utilisation de nœuds de travail exécutant RHEL/Red Hat Enterprise Linux CoreOS (RHCOS) avec des volumes persistants FC, spécifiez le `discard` L'option mountOption dans StorageClass permet d'effectuer une récupération d'espace en ligne. Se référer à https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/managing_file_systems/discarding-unused-blocks_managing-file-systems["Documentation Red Hat"^] .


[role="tabbed-block"]
====
.RHEL 8+
--
. Installez les paquets système suivants :
+
[listing]
----
sudo yum install -y lsscsi device-mapper-multipath
----
. Activer le multipathing :
+
[listing]
----
sudo mpathconf --enable --with_multipathd y --find_multipaths n
----
+

NOTE: Assurer `/etc/multipath.conf` contient `find_multipaths no` sous `defaults` .

. Assurez-vous que `multipathd` est en cours d'exécution :
+
[listing]
----
sudo systemctl enable --now multipathd
----


--
.Ubuntu
--
. Installez les paquets système suivants :
+
[listing]
----
sudo apt-get install -y lsscsi sg3-utils multipath-tools scsitools
----
. Activer le multipathing :
+
[listing]
----
sudo tee /etc/multipath.conf <<-EOF
defaults {
    user_friendly_names yes
    find_multipaths no
}
EOF
sudo systemctl enable --now multipath-tools.service
sudo service multipath-tools restart
----
+

NOTE: Assurer `/etc/multipath.conf` contient `find_multipaths no` sous `defaults` .

. Assurez-vous que `multipath-tools` est activé et en cours d'exécution :
+
[listing]
----
sudo systemctl status multipath-tools
----


--
====